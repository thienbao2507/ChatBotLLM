from openai import OpenAI
from dotenv import load_dotenv
from mongo_module import find_products_by_keyword
from chat_engine import is_news_query, extract_url, get_latest_news, summarize_article
from gradioInterface import build_gradio_ui
import os
import fitz

customer_mode = {"enabled": False}
pdf_context = {"content": ""}

def toggle_customer_mode(toggle):
    customer_mode["enabled"] = toggle
    return f"T∆∞ v·∫•n kh√°ch h√†ng: {'B·∫¨T' if toggle else 'T·∫ÆT'}"

def upload_pdf(file):
    text = ""
    try:
        doc = fitz.open(file.name)
        for page in doc:
            text += page.get_text()
        pdf_context["content"] = text
        return "‚úÖ ƒê√£ t·∫£i v√† ƒë·ªçc n·ªôi dung PDF th√†nh c√¥ng!"
    except Exception as e:
        return f"‚ùå L·ªói ƒë·ªçc PDF: {e}"

# Load API Key
load_dotenv()
client = OpenAI(
    api_key=os.getenv("GEMINI_API_KEY"),
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

def find_products_by_keyword(keyword):
    sample_products = [
        {
            "name": "iPhone 15 Pro Max",
            "brand": "Apple",
            "price": 32990000,
            "discount": 10,
            "description": "Flagship m·∫°nh m·∫Ω t·ª´ Apple"
        },
        {
            "name": "Samsung Galaxy S24 Ultra",
            "brand": "Samsung",
            "price": 28990000,
            "discount": 12,
            "description": "ƒêi·ªán tho·∫°i cao c·∫•p, camera t·ªët"
        }
    ]

    result = ""
    for product in sample_products:
        if keyword.lower() in product["name"].lower() or keyword.lower() in product["brand"].lower():
            discounted_price = int(product["price"] * (1 - product["discount"]/100))
            result += f"\nüì± {product['name']} ({product['brand']})\n"
            result += f"üí∞ Gi√°: {product['price']:,}ƒë (-{product['discount']}%) ‚Üí {discounted_price:,}ƒë\n"
            result += f"‚ÑπÔ∏è M√¥ t·∫£: {product['description']}\n---\n"

    return result if result else "‚ùå Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."

def chat_with_gemini(message, history):
    if customer_mode["enabled"]:
        return find_products_by_keyword(message)

    if is_news_query(message):
        raw_news = get_latest_news()
        prompt = f"H√£y t√≥m t·∫Øt v√† ph√¢n t√≠ch c√°c s·ª± ki·ªán sau:\n\n{raw_news}"
        response = client.chat.completions.create(
            model="gemini-2.0-flash",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

    url = extract_url(message)
    if url:
        text = summarize_article(url)
        if text.startswith("‚ùå"): return text
        prompt = f"T√≥m t·∫Øt b√†i b√°o sau:\n\n{text}"
        response = client.chat.completions.create(
            model="gemini-2.0-flash",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

    prompt = pdf_context["content"] and f"D·ª±a v√†o t√†i li·ªáu sau, tr·∫£ l·ªùi:\n\n{pdf_context['content']}\n\nC√¢u h·ªèi: {message}" or message
    messages = [{"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω AI th√¢n thi·ªán."}]
    for user, bot in history:
        messages.extend([
            {"role": "user", "content": user},
            {"role": "assistant", "content": bot}
        ])
    messages.append({"role": "user", "content": prompt})

    stream = client.chat.completions.create(model="gemini-2.0-flash", messages=messages, stream=True)
    reply = ""
    for chunk in stream:
        if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
            reply += chunk.choices[0].delta.content
    return reply

# Kh·ªüi ch·∫°y app
app = build_gradio_ui(chat_with_gemini, upload_pdf, toggle_customer_mode)
app.launch()
